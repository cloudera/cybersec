{
  "name" : "SYBERCES",
  "label" : "Cybersec",
  "description" : "Cyber security project.",
  "version" : "1.0",
  "compatibility" : { "cdhVersion" : { "min" : "7.1.6" } },
  "runAs" : {
    "user" : "cybersec",
    "group" : "cybersec",
    "principal" : "cybersec"
   },
   "icon" : "images/cybersec.svg",
   "parcel" : {
    "repoUrl" : "https://archive.cloudera.com/p/csa/1.6/parcels",
    "requiredTags" : ["cybersec", "cdh"],
    "optionalTags" : ["cybersec-plugin"]
  },
  "serviceDependencies" : [
    {
          "name" : "FLINK",
          "required" : "false"
     },
     {
          "name" : "HDFS",
          "required" : "false"
     },
     {
          "name" : "YARN",
          "required" : "false"
      },
      {
            "name": "ZOOKEEPER",
            "required": "false"
      },
      {
           "name": "HIVE",
           "required": "false"
      },
      {
           "name": "ATLAS",
           "required": "false"
      },
      {
           "name": "SCHEMAREGISTRY",
           "required": "false"
      }
  ],
  "dependencyExtensions": [
    {
      "type": "atlasDependency",
      "extensionId": "atlas_dependency"
    },
    {
      "type": "kafkaDependency",
      "extensionId": "kafka_dependency"
    }
  ],
  "kerberos": "${kerberos.auth.enabled}",
  "parameters" : [
    {
      "name": "kerberos.auth.enabled",
      "label": "Enable Kerberos Authentication",
      "description": "Enables Kerberos authentication for Cybersec",
      "type": "boolean",
      "default": "false",
      "configurableInWizard": true
    },
    {
      "name" : "jobmanager_heap_size",
      "label" : "JobManager Heap Size",
      "description" : "JVM heap size for the JobManager",
      "configName" : "jobmanager.heap.size",
      "default" : "1073741824",
      "type" : "memory",
      "unit" : "bytes",
      "required" : "true"
    },
    {
      "name" : "taskmanager_memory_process_size",
      "label" : "TaskManager Process Memory Size",
      "description" : "This includes all the memory that a TaskExecutor consumes, consisting of Total Cybersec Memory, JVM Metaspace, and JVM Overhead. On containerized setups, this should be set to the container memory. See also 'taskmanager.memory.cybersec.size' for total Cybersec memory size configuration.",
      "configName" : "taskmanager.memory.process.size",
      "default" : "2147483648",
      "type" : "memory",
      "unit" : "bytes",
      "required" : "true"
    },
    {
      "name" : "taskmanager_managed_memory_fraction",
      "label" : "TaskManager Managed Memory Fraction",
      "description" : "Fraction of Total Cybersec Memory to be used as Managed Memory, if Managed Memory size is not explicitly specified. Managed memory is used by Cybersec operators (caching, sorting, hashtables) and state backends (RocksDB).",
      "configName" : "taskmanager.memory.managed.fraction",
      "default" : "0.4",
      "type" : "double",
      "required" : "true"
    },
    {
      "name" : "taskmanager_number_of_task_slots",
      "label" : "TaskManager Number of Task Slots",
      "description" : "The number of parallel operator or user function instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager's machine has (e.g., equal to the number of cores, or half the number of cores).",
      "configName" : "taskmanager.numberOfTaskSlots",
      "default" : "1",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "parallelism_default",
      "label" : "Default Parallelism",
      "description" : "Default parallelism for jobs",
      "configName" : "parallelism.default",
      "default" : "1",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "yarn_maximum_failed_containers",
      "label" : "Maximum Failed Containers for YARN",
      "description" : "Maximum number of containers the system is going to reallocate in case of a failure.",
      "configName" : "yarn.maximum-failed-containers",
      "default" : "100",
      "type" : "long",
      "required" : "false"
    },
    {
      "name" : "yarn_application_attempts",
      "label" : "Maximum ApplicationMaster Attempts for YARN",
      "description" : "Number of ApplicationMaster restarts. Note that that the entire Cybersec cluster will restart and the YARN Client will loose the connection. Also, the JobManager address will change and youâ€™ll need to set the JM host:port manually. It is recommended to leave this option at 1.",
      "configName" : "yarn.application-attempts",
      "default" : "5",
      "type" : "long",
      "required" : "false"
    },
    {
      "name" : "yarn_container_start_command_template",
      "label" : "Yarn Container Command template",
      "description" : "Specifies the command template for yarn container starts. Should only be overriden by expert users.",
      "configName" : "yarn.container-start-command-template",
      "default" : "%java% %jvmmem% %jvmopts% -DyarnContainerId=$CONTAINER_ID %logging% %class% %args% %redirects%",
      "type" : "string",
      "required" : "false"
    },
    {
      "name" : "yarn_tags",
      "label" : "YARN Tags",
      "description" : "A comma-separated list of tags to apply to the Cybersec YARN application.",
      "configName" : "yarn.tags",
      "default" : "cybersec",
      "type" : "string",
      "required" : "false"
    },
    {
      "name" : "state_backend",
      "label" : "State Backend",
      "description" : "The state backend to be used to store and checkpoint state.",
      "configName" : "state.backend",
      "default" : "FILESYSTEM",
      "type" : "string_enum",
      "validValues" : ["FILESYSTEM", "ROCKSDB"],
      "required" : "false"
    },
    {
      "name" : "state_checkpoints_dir",
      "label" : "State Checkpoints Directory (HDFS)",
      "description" : "The default directory used for storing the data files and meta data of checkpoints in a Cybersec supported filesystem. After changing this location please execute the `Create State Checkpoint Directory` action of the Cybersec service.",
      "configName" : "state.checkpoints.dir",
      "default" : "/user/cybersec/checkpoints",
      "type" : "path",
      "pathType" : "serviceSpecific",
      "required" : "false",
      "translateToBaseHdfs" : "true"
    },
    {
      "name" : "state_savepoints_dir",
      "label" : "State Savepoints Directory (HDFS)",
      "description" : "The default directory used for storing the data files and meta data of checkpoints in a Cybersec supported filesystem. After changing this location please execute the `Create State Savepoint Directory` action of the Cybersec service.",
      "configName" : "state.savepoints.dir",
      "default" : "/user/cybersec/savepoints",
      "type" : "path",
      "pathType" : "serviceSpecific",
      "required" : "false",
      "translateToBaseHdfs" : "true"
    },
    {
      "name" : "state_backend_incremental",
      "label" : "Incremental Checkpoints",
      "description" : "Option whether the state backend should create incremental checkpoints, if possible. For an incremental checkpoint, only a diff from the previous checkpoint is stored, rather than the complete checkpoint state. Some state backends may not support incremental checkpoints and ignore this option.",
      "configName" : "state.backend.incremental",
      "default" : "true",
      "type" : "boolean",
      "required" : "true"
    },
    {
      "name" : "state_backend_local_recovery",
      "label" : "Local State Recovery",
      "description" : "This option configures local recovery for this state backend. By default, local recovery is deactivated. Local recovery currently only covers keyed state backends. Currently, MemoryStateBackend does not support local recovery and ignore this option.",
      "configName" : "state.backend.local-recovery",
      "default" : "true",
      "type" : "boolean",
      "required" : "true"
    },
    {
      "name" : "state_backend_rocksdb_memory_managed",
      "label" : "RocksDB Memory Management",
      "description" : "If set, the RocksDB state backend will automatically configure itself to use the managed memory budget of the task slot, and divide the memory over write buffers, indexes, block caches, etc. That way, the three major uses of memory of RocksDB will be capped.",
      "configName" : "state.backend.rocksdb.memory.managed",
      "default" : "true",
      "type" : "boolean",
      "required" : "true"
    },
    {
      "name" : "state_backend_rocksdb_memory_high_prio_ratio",
      "label" : "RocksDB High-Prio Memory Fraction",
      "description" : "The fraction of cache memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.",
      "configName" : "state.backend.rocksdb.memory.high-prio-pool-ratio",
      "default" : "0.1",
      "type" : "double",
      "required" : "true"
    },
    {
      "name" : "state_backend_rocksdb_memory_write_buffer_ratio",
      "label" : "RocksDB Write Buffer Memory Fraction",
      "description" : "The maximum amount of memory that write buffers may take, as a fraction of the total shared memory. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.",
      "configName" : "state.backend.rocksdb.memory.write-buffer-ratio",
      "default" : "0.5",
      "type" : "double",
      "required" : "true"
    },
    {
      "name" : "state_backend_rocksdb_timer_service_factory",
      "label" : "RocksDB StateBackend Timer Service Factory",
      "description" : "This determines the factory for timer service state implementation. Options are either HEAP (heap-based, default) or ROCKSDB for an implementation based on RocksDB.",
      "configName" : "state.backend.rocksdb.timer-service.factory",
      "default" : "ROCKSDB",
      "type" : "string_enum",
      "validValues" : ["HEAP", "ROCKSDB"],
      "required" : "true"
    },
    {
      "name" : "state_backend_rocksdb_predefined_options",
      "label" : "Predefined options for RocksDB state backend",
      "description" : "The predefined settings for RocksDB DBOptions and ColumnFamilyOptions by Cybersec community. Current supported candidate predefined-options are DEFAULT, SPINNING_DISK_OPTIMIZED, SPINNING_DISK_OPTIMIZED_HIGH_MEM or FLASH_SSD_OPTIMIZED. Note that user customized options and options from the RocksDBOptionsFactory are applied on top of these predefined ones.",
      "configName" : "state.backend.rocksdb.predefined-options",
      "default" : "DEFAULT",
      "type" : "string_enum",
      "validValues" : ["DEFAULT", "SPINNING_DISK_OPTIMIZED", "SPINNING_DISK_OPTIMIZED_HIGH_MEM", "FLASH_SSD_OPTIMIZED"],
      "required" : "true"
    },
    {
      "name" : "state_checkpoints_num_retained",
      "label" : "Number of Checkpoints to Retain",
      "description" : "The maximum number of completed checkpoints to retain.",
      "configName" : "state.checkpoints.num-retained",
      "default" : "3",
      "type" : "long",
      "required" : "false"
    },
    {
      "name" : "jobmanager_archive_fs_dir",
      "label" : "JobManager Archive Directory (HDFS)",
      "description" : "Directory to upload completed jobs to. (Add this directory to the list of monitored directories of the HistoryServer as well.) After changing this location please execute the `Create JobManager Archive Directory` action of the Cybersec service.",
      "configName" : "jobmanager.archive.fs.dir",
      "default" : "/user/cybersec/applicationHistory",
      "type" : "path",
      "pathType" : "serviceSpecific",
      "required" : "true",
      "translateToBaseHdfs" : "true"
    },
    {
      "name" : "security_kerberos_login_contexts",
      "label" : "Kerberos Login Contexts",
      "description" : "A comma-separated list of login contexts to provide the Kerberos credentials to (for example, `Client,KafkaClient` to use the credentials for ZooKeeper authentication and for Kafka authentication)",
      "configName" : "security.kerberos.login.contexts",
      "default" : ["Client", "KafkaClient", "RegistryClient"],
      "type" : "string_array",
      "separator" : ",",
      "required" : "false"
    },
    {
      "name" : "security_kerberos_login_use_ticket_cache",
      "label" : "Kerberos Use Ticket Cache",
      "description" : "Indicates whether to read from your Kerberos ticket cache.",
      "configName" : "security.kerberos.login.use-ticket-cache",
      "type" : "boolean",
      "default" : "true",
      "required" : "false"
    },
    {
      "name" : "execution.target",
      "label" : "Executor",
      "description" : "The name of the executor to be used for executing the given job.",
      "configName" : "execution.target",
      "default" : "yarn-per-job",
      "type" : "string_enum",
      "validValues" : ["yarn-per-job", "yarn-session"],
      "required" : "true"
    },
    {
      "name" : "high_availability",
      "label" : "High Availability Service",
      "description" : "Defines high-availability mode used for the cluster execution. To enable high-availability, set this mode to 'ZOOKEEPER' or specify FQN of factory class.",
      "configName" : "high-availability",
      "default" : "ZOOKEEPER",
      "type" : "string_enum",
      "validValues" : ["NONE", "ZOOKEEPER"],
      "required" : "false"
    },
    {
      "name" : "high_availability_storage_dir",
      "label" : "High Availability Storage Directory",
      "description" : "File system path (URI) where Cybersec persists metadata in high-availability setups. After changing this location please execute the `Create HA Directory` action of the Cybersec service.",
      "configName" : "high-availability.storageDir",
      "default" : "/user/cybersec/ha",
      "type" : "path",
      "pathType" : "serviceSpecific",
      "required" : "false",
      "translateToBaseHdfs" : "true"
    },
    {
      "name" : "high_availability_zookeeper_client_acl",
      "label" : "High Availability Zookeeper client ACL",
      "description" : "Defines the ACL (open|creator) to be configured on ZK node. The configuration value can be set to 'creator' if the ZooKeeper server configuration has the 'authProvider' property mapped to use SASLAuthenticationProvider and the cluster is configured to run in secure mode (Kerberos).",
      "configName" : "high-availability.zookeeper.client.acl",
      "default" : "open",
      "type" : "string",
      "required" : "false"
    },
    {
      "name" : "taskmanager_network_memory_fraction",
      "label" : "Network Buffer JVM Memory Fraction",
      "description" : "Fraction of JVM memory to use for network buffers. This determines how many streaming data exchange channels a TaskManager can have at the same time and how well buffered the channels are. If a job is rejected or you get a warning that the system has not enough buffers available, increase this value or the min/max values below. Also note, that 'taskmanager.memory.network.min' and 'taskmanager.memory.network.max' may override this fraction.",
      "configName" : "taskmanager.memory.network.fraction",
      "default" : "0.1",
      "type" : "double",
      "required" : "true"
    },
    {
      "name" : "taskmanager_network_memory_max",
      "label" : "Network Buffer Memory Max",
      "description" : "Max Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Cybersec Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value.",
      "configName" : "taskmanager.memory.network.max",
      "default" : "2147483648",
      "type" : "memory",
      "unit" : "bytes",
      "required" : "true"
    },
    {
      "name" : "env_java_opts_jobmanager",
      "label" : "JobManager JVM Options",
      "description" : "Java options to start the JVM of the JobManager with.",
      "configName" : "env.java.opts.jobmanager",
      "default" : "",
      "type" : "string",
      "required" : "false"
    },
    {
      "name" : "env_java_opts_taskmanager",
      "label" : "TaskManager JVM Options",
      "description" : "Java options to start the JVM of the TaskManager with.",
      "configName" : "env.java.opts.taskmanager",
      "default" : "",
      "type" : "string",
      "required" : "false"
    },
    {
      "name" : "historyserver_cli_fallback",
      "label" : "CLI global dashboard fallback",
      "description" : "Allow the CLI to fall back to the global dashboard endpoint to access Cybersec jobs when the jobmanager address or yarn appId are not defined.",
      "configName" : "historyserver.cli.fallback",
      "default" : "true",
      "type" : "boolean",
      "required" : "false"
    },
    {
      "name" : "execution_buffer_timeout",
      "label" : "Network Buffer Timeout (milliseconds)",
      "description" : "The maximum time frequency (ms) for the flushing of the output buffers. By default the output buffers flush frequently to provide low latency and to aid smooth developer experience.",
      "configName" : "execution.buffer-timeout",
      "default" : "100",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "execution_snapshot_compression",
      "label" : "Enable Checkpoint Compression",
      "description" : "Tells if we should use compression for the state snapshot data or not.",
      "configName" : "execution.checkpointing.snapshot-compression",
      "default" : "false",
      "type" : "boolean",
      "required" : "true"
    },
    {
      "name" : "pipeline_auto_watermark_interval",
      "label" : "Automatic Watermark Interval (milliseconds)",
      "description" : "The interval of the automatic watermark emission. Watermarks are used throughout the streaming system to keep track of the progress of time. They are used, for example, for time based windowing.",
      "configName" : "pipeline.auto-watermark-interval",
      "default" : "200",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "pipeline_generic_types",
      "label" : "Allow Generic Types",
      "description" : "If the use of generic types is disabled, Cybersec will throw an UnsupportedOperationException whenever it encounters a data type that would go through Kryo for serialization.",
      "configName" : "pipeline.generic-types",
      "default" : "true",
      "type" : "boolean",
      "required" : "true"
    },
    {
      "name" : "pipeline_max_parallelism",
      "label" : "Max Parallelism",
      "description" : "The program-wide maximum parallelism used for operators which haven't specified a maximum parallelism. The maximum parallelism specifies the upper limit for dynamic scaling and the number of key groups used for partitioned state.",
      "configName" : "pipeline.max-parallelism",
      "type" : "long",
      "required" : "false"
    },
    {
      "name" : "pipeline_object_reuse",
      "label" : "Enable Object Reuse",
      "description" : "When enabled objects that Cybersec internally uses for deserialization and passing data to user-code functions will be reused. Keep in mind that this can lead to bugs when the user-code function of an operation is not aware of this behaviour.",
      "configName" : "pipeline.object-reuse",
      "default" : "false",
      "type" : "boolean",
      "required" : "true"
    },
    {
      "name" : "externalized_checkpoint_retention",
      "label" : "Externalized Checkpoint Retention",
      "description" : "The mode defines how an externalized checkpoint should be cleaned up on job cancellation. If you choose to retain externalized checkpoints on cancellation you have to handle checkpoint clean up manually when you cancel the job as well",
      "configName" : "execution.checkpointing.externalized-checkpoint-retention",
      "default" : "RETAIN_ON_CANCELLATION",
      "type" : "string_enum",
      "validValues" : ["RETAIN_ON_CANCELLATION", "DELETE_ON_CANCELLATION"],
      "required" : "true"
    },
    {
      "name" : "checkpointing_interval",
      "label" : "Checkpointing Interval (milliseconds)",
      "description" : "Gets the interval in which checkpoints are periodically scheduled. This setting defines the base interval. Checkpoint triggering may be delayed by the settings execution.checkpointing.max-concurrent-checkpoints and execution.checkpointing.min-pause",
      "configName" : "execution.checkpointing.interval",
      "type" : "long",
      "required" : "false"
    },
    {
      "name" : "max_concurrent_checkpoints",
      "label" : "Max Concurrent Checkpoints",
      "description" : "The maximum number of checkpoint attempts that may be in progress at the same time. If this value is n, then no checkpoints will be triggered while n checkpoint attempts are currently in flight. For the next checkpoint to be triggered, one checkpoint attempt would need to finish or expire.",
      "configName" : "execution.checkpointing.max-concurrent-checkpoints",
      "default" : "1",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "checkpointing_min_pause",
      "label" : "Min Pause Between Checkpoints (milliseconds)",
      "description" : "The minimal pause between checkpointing attempts. This setting defines how soon thecheckpoint coordinator may trigger another checkpoint after it becomes possible to triggeranother checkpoint with respect to the maximum number of concurrent checkpoints(see execution.checkpointing.max-concurrent-checkpoints).",
      "configName" : "execution.checkpointing.min-pause",
      "default" : "0",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "checkpointing_mode",
      "label" : "Checkpointing Mode",
      "description" : "The checkpointing mode (exactly-once vs. at-least-once).",
      "configName" : "execution.checkpointing.mode",
      "default" : "EXACTLY_ONCE",
      "type" : "string_enum",
      "validValues" : ["EXACTLY_ONCE", "AT_LEAST_ONCE"],
      "required" : "true"
    },
    {
      "name" : "checkpointing_timeout",
      "label" : "Checkpointing Timeout (milliseconds)",
      "description" : "The maximum time that a checkpoint may take before being discarded.",
      "configName" : "execution.checkpointing.timeout",
      "default" : "60000",
      "type" : "long",
      "required" : "true"
    },
    {
      "name" : "jobmanager_per_user_archive",
      "label" : "Enable user specific archive subdirectory",
      "description" : "Boolean flag indicating whether the job archive should be written to a user specific subdirectory.",
      "configName" : "jobmanager.archive.per-user",
      "default" : "true",
      "type" : "boolean"
    },
    {
      "name" : "atlas_collection_enabled",
      "label" : "Enable Atlas Metadata Collection",
      "description" : "When enabling this make sure that your Cybersec gateway nodes also have the Atlas gateway role assigned.",
      "configName" : "atlas.collection.enabled",
      "default" : "false",
      "type" : "boolean",
      "required" : "false"
    },
    {
      "name" : "atlas_metadata_namespace",
      "label" : "Atlas Metadata Namespace",
      "description" : "Metadata Namespace used in Atlas for Cybersec applications.",
      "configName" : "atlas.metadata.namespace",
      "default" : "cm",
      "type" : "string",
      "required" : "true"
    }
  ],
  "gateway" : {
    "alternatives" : {
      "name" : "cybersec-conf",
      "linkRoot" : "/etc/cybersec",
      "priority" : 50
    },
    "scriptRunner" : {
      "program" : "scripts/control.sh",
      "environmentVariables" : {
         "HIVE_SERVICE" : "${dependency:HIVE}",
         "ATLAS_SERVICE" : "${dependency:ATLAS}",
         "ATLAS_REST_URL": "${atlas_rest_url}",
         "ATLAS_KAFKA_BOOTSTRAP_SERVERS": "${atlas_kafka_bootstrap_servers}",
         "ATLAS_KAFKA_SECURITY_PROTOCOL": "${atlas_kafka_security_protocol}",
         "ATLAS_KAFKA_ZK_CONNECT": "${atlas_kafka_zk_connect}",
         "ATLAS_METADATA_NAMESPACE": "${atlas_metadata_namespace}",
         "KERBEROS_ENABLED": "${kerberos.auth.enabled}"
      },
      "args" : [ "client" ]
    },
    "sslClient": {
      "truststoreLocationConfigName" : "security.ssl.rest.truststore",
      "truststorePasswordConfigName" : "security.ssl.rest.truststore-password"
    },
    "configWriter" : {
      "generators" : [
        {
          "filename": "conf/generator.properties",
          "configFormat": "properties",
          "includedParams": [
            "ssl_client_truststore_location",
            "ssl_client_truststore_password"
          ],
            "additionalConfigs": [
              {
                "key": "schema.registry.service.name.2",
                "value": "${dependency:SCHEMAREGISTRY}"
              },
              {
                  "key": "kafka.bootstrap.servers",
                  "value": "${kafka_brokers_list}"
              }
            ]
        }
      ]
    }
  }
}
